# -*- coding: utf-8 -*-
"""multimodal_embedding.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aAzCJ-hR5ybW2IFUIxvWxppR1Rrrhvg2
"""

!pip install -q transformers torch torchvision pillow
!pip install -q sentence-transformers
!pip install -q open_clip_torch
!pip install -q qdrant-client
!pip install -q accelerate
!pip install -q bitsandbytes

import torch
import numpy as np
from PIL import Image
import open_clip
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
import json
from typing import List, Dict, Tuple
import hashlib
from google.colab import userdata

# Cell 3: Initialize Models
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

clip_model, _, clip_preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')
clip_model = clip_model.to(device)
clip_model.eval()

text_encoder = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')

tokenizer = open_clip.get_tokenizer('ViT-B-32')

def load_policy_document(filepath='policy.txt'):
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            policy_text = f.read()
        return policy_text
    except FileNotFoundError:
        print(f"Policy file not found. Creating sample policy...")
        sample_policy = """
        1. No misleading claims or false advertising
        2. No adult or violent content
        3. No trademark violations
        4. Clear disclosure of terms and conditions
        5. No prohibited substances or illegal content
        6. Accurate product representations
        7. No discriminatory content
        8. Compliance with data privacy regulations
        """
        with open(filepath, 'w') as f:
            f.write(sample_policy)
        return sample_policy

policy_text = load_policy_document()

def chunk_policy_text(text, chunk_size=512, overlap=50):
    words = text.split()
    chunks = []
    for i in range(0, len(words), chunk_size - overlap):
        chunk = ' '.join(words[i:i + chunk_size])
        chunks.append(chunk)
    return chunks

policy_chunks = chunk_policy_text(policy_text)
print(f"Created {len(policy_chunks)} policy chunks")

qdrant_client = QdrantClient(":memory:")

collections = {
    "policy_text": 768,
    "policy_visual": 512,
    "ad_content": 512
}

for collection_name, dim in collections.items():
    qdrant_client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=dim, distance=Distance.COSINE)
    )

def embed_policy_chunks(chunks):
    embeddings = text_encoder.encode(chunks, convert_to_tensor=True)
    return embeddings.cpu().numpy()

policy_embeddings = embed_policy_chunks(policy_chunks)

for idx, (chunk, embedding) in enumerate(zip(policy_chunks, policy_embeddings)):
    qdrant_client.upsert(
        collection_name="policy_text",
        points=[
            PointStruct(
                id=idx,
                vector=embedding.tolist(),
                payload={"text": chunk, "chunk_id": idx}
            )
        ]
    )

print(f"Indexed {len(policy_chunks)} policy chunks")

def embed_image(image_path_or_pil):
    if isinstance(image_path_or_pil, str):
        image = Image.open(image_path_or_pil).convert('RGB')
    else:
        image = image_path_or_pil.convert('RGB')

    image_input = clip_preprocess(image).unsqueeze(0).to(device)

    with torch.no_grad():
        image_features = clip_model.encode_image(image_input)
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)

    return image_features.cpu().numpy().squeeze()

def embed_text_clip(text):
    text_tokens = tokenizer([text]).to(device)

    with torch.no_grad():
        text_features = clip_model.encode_text(text_tokens)
        text_features = text_features / text_features.norm(dim=-1, keepdim=True)

    return text_features.cpu().numpy().squeeze()

def embed_text_semantic(text):
    embedding = text_encoder.encode(text, convert_to_tensor=True)
    return embedding.cpu().numpy()

def find_relevant_policies(query_text, query_image=None, top_k=3):
    results = {}

    text_embedding = embed_text_semantic(query_text)
    text_results = qdrant_client.search(
        collection_name="policy_text",
        query_vector=text_embedding.tolist(),
        limit=top_k
    )
    results['text_matches'] = [(hit.payload['text'], hit.score) for hit in text_results]

    if query_image is not None:
        image_embedding = embed_image(query_image)
        clip_text_embedding = embed_text_clip(query_text)

        combined_embedding = (image_embedding + clip_text_embedding) / 2

        visual_policy_keywords = [
            "visual content", "imagery", "graphics", "adult content",
            "violent content", "misleading visuals", "trademark"
        ]

        visual_scores = []
        for keyword in visual_policy_keywords:
            keyword_embedding = embed_text_clip(keyword)
            score = np.dot(combined_embedding, keyword_embedding)
            visual_scores.append((keyword, float(score)))

        results['visual_concerns'] = sorted(visual_scores, key=lambda x: x[1], reverse=True)[:3]

    return results

def calculate_compliance_score(ad_text, ad_image=None):
    base_score = 10.0
    violations = []

    relevant_policies = find_relevant_policies(ad_text, ad_image)

    prohibited_terms = [
        "guaranteed", "100%", "risk-free", "miracle", "instant results",
        "limited time", "act now", "exclusive", "secret"
    ]

    ad_text_lower = ad_text.lower()
    for term in prohibited_terms:
        if term in ad_text_lower:
            base_score -= 1.5
            violations.append(f"Prohibited term found: '{term}'")

    if ad_image is not None:
        image_embedding = embed_image(ad_image)

        concerning_concepts = ["violence", "adult", "weapons", "drugs"]
        for concept in concerning_concepts:
            concept_embedding = embed_text_clip(concept)
            similarity = np.dot(image_embedding, concept_embedding)
            if similarity > 0.25:
                base_score -= 2.0
                violations.append(f"Potential {concept} content detected")

    for policy_text, relevance_score in relevant_policies['text_matches']:
        if relevance_score > 0.7:
            base_score -= 0.5

    return {
        "score": max(0, min(10, base_score)),
        "violations": violations,
        "relevant_policies": relevant_policies
    }

def load_llama_model():
    hf_token = userdata.get('HF_TOKEN')

    quantization_config = BitsAndBytesConfig(
        load_in_4bit=True,
        bnb_4bit_compute_dtype=torch.float16,
        bnb_4bit_quant_type="nf4",
        bnb_4bit_use_double_quant=True
    )

    model_id = "meta-llama/Llama-2-7b-chat-hf"

    tokenizer = AutoTokenizer.from_pretrained(
        model_id,
        token=hf_token,
        use_fast=True
    )
    tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        model_id,
        token=hf_token,
        quantization_config=quantization_config,
        device_map="auto",
        torch_dtype=torch.float16
    )

    return model, tokenizer

def generate_compliance_explanation(ad_content, violations, model, tokenizer):
    prompt = f"""You are an ad compliance expert. Analyze this ad content against our policies.

Ad Content: {ad_content}

Detected Issues: {', '.join(violations) if violations else 'None'}

Relevant Policies:
{policy_text[:500]}

Provide a brief compliance assessment with specific policy violations and suggestions for improvement.
Keep response under 150 words."""

    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)

    with torch.no_grad():
        outputs = model.generate(
            inputs.input_ids.to(model.device),
            max_new_tokens=200,
            temperature=0.7,
            do_sample=True,
            top_p=0.95
        )

    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    return response.split("Provide a brief")[1] if "Provide a brief" in response else response

class AdComplianceChecker:
    def __init__(self, use_llm=False):
        self.use_llm = use_llm
        if use_llm:
            print("Loading Llama model...")
            self.llm_model, self.llm_tokenizer = load_llama_model()
            print("Model loaded!")

    def analyze_ad(self, ad_text, ad_image_path=None):
        print("Analyzing ad compliance...")

        compliance_result = calculate_compliance_score(ad_text, ad_image_path)

        analysis = {
            "compliance_score": compliance_result["score"],
            "pass": compliance_result["score"] >= 7,
            "violations": compliance_result["violations"],
            "relevant_policies": compliance_result["relevant_policies"]["text_matches"][:2]
        }

        if self.use_llm and compliance_result["violations"]:
            explanation = generate_compliance_explanation(
                ad_text,
                compliance_result["violations"],
                self.llm_model,
                self.llm_tokenizer
            )
            analysis["explanation"] = explanation

        return analysis

def test_compliance_system():
    test_ad_text = "Get rich quick! Guaranteed 100% returns with our miracle investment system. Act now - limited time offer!"

    checker = AdComplianceChecker(use_llm=False)

    result = checker.analyze_ad(test_ad_text)

    print(f"Compliance Score: {result['compliance_score']}/10")
    print(f"Status: {'PASS' if result['pass'] else 'FAIL'}")
    print(f"\nViolations Found:")
    for violation in result['violations']:
        print(f"  - {violation}")
    print(f"\nRelevant Policies:")
    for policy, score in result['relevant_policies']:
        print(f"  - {policy[:100]}... (relevance: {score:.2f})")

test_compliance_system()

def process_ad_batch(ads_data):
    checker = AdComplianceChecker(use_llm=False)
    results = []

    for ad in ads_data:
        result = checker.analyze_ad(
            ad.get('text', ''),
            ad.get('image_path', None)
        )
        results.append({
            'ad_id': ad.get('id', 'unknown'),
            'compliance': result
        })

    return results

def save_embeddings(embeddings, metadata, filename="embeddings_cache.npz"):
    np.savez_compressed(
        filename,
        embeddings=embeddings,
        metadata=json.dumps(metadata)
    )
    print(f"Saved embeddings to {filename}")

def load_embeddings(filename="embeddings_cache.npz"):
    data = np.load(filename, allow_pickle=True)
    embeddings = data['embeddings']
    metadata = json.loads(str(data['metadata']))
    return embeddings, metadata

from dataclasses import dataclass

@dataclass
class PolicyEmbeddings:
    text_embeddings: np.ndarray
    clip_text_embeddings: np.ndarray
    chunks: List[str]
    metadata: Dict

def generate_policy_embeddings(policy_text):
    chunks = chunk_policy_text(policy_text)

    # Generate text embeddings using sentence transformer
    text_embeddings = text_encoder.encode(chunks, convert_to_tensor=False, show_progress_bar=True)

    # Generate CLIP text embeddings for multimodal alignment
    clip_embeddings = []
    for chunk in chunks:
        clip_emb = embed_text_clip(chunk[:77])  # CLIP has 77 token limit
        clip_embeddings.append(clip_emb)
    clip_embeddings = np.array(clip_embeddings)

    policy_emb = PolicyEmbeddings(
        text_embeddings=text_embeddings,
        clip_text_embeddings=clip_embeddings,
        chunks=chunks,
        metadata={
            'num_chunks': len(chunks),
            'models': {
                'text': 'all-mpnet-base-v2',
                'clip': 'ViT-B-32'
            }
        }
    )

    # Save embeddings
    save_embeddings(
        text_embeddings,
        {'chunks': chunks, 'type': 'text'},
        'policy_text_embeddings.npz'
    )

    save_embeddings(
        clip_embeddings,
        {'chunks': chunks, 'type': 'clip'},
        'policy_clip_embeddings.npz'
    )

    return policy_emb

# Generate and store policy embeddings
policy_embeddings = generate_policy_embeddings(policy_text)
print(f"Generated embeddings for {len(policy_embeddings.chunks)} policy chunks")

class MultimodalPolicyIndex:
    def __init__(self, policy_embeddings: PolicyEmbeddings):
        self.policy_embeddings = policy_embeddings
        self.qdrant = QdrantClient(":memory:")
        self._create_collections()
        self._index_policies()

    def _create_collections(self):
        collections = {
            "policy_semantic": 768,  # MPNet dimension
            "policy_clip": 512,      # CLIP dimension
            "ad_multimodal": 512,    # For ad content
        }

        for name, dim in collections.items():
            self.qdrant.create_collection(
                collection_name=name,
                vectors_config=VectorParams(size=dim, distance=Distance.COSINE)
            )

    def _index_policies(self):
        # Index semantic embeddings
        for idx, (emb, chunk) in enumerate(zip(
            self.policy_embeddings.text_embeddings,
            self.policy_embeddings.chunks
        )):
            self.qdrant.upsert(
                collection_name="policy_semantic",
                points=[PointStruct(
                    id=idx,
                    vector=emb.tolist(),
                    payload={"text": chunk, "chunk_id": idx}
                )]
            )

        # Index CLIP embeddings
        for idx, (emb, chunk) in enumerate(zip(
            self.policy_embeddings.clip_text_embeddings,
            self.policy_embeddings.chunks
        )):
            self.qdrant.upsert(
                collection_name="policy_clip",
                points=[PointStruct(
                    id=idx,
                    vector=emb.tolist(),
                    payload={"text": chunk, "chunk_id": idx}
                )]
            )

    def search_policies(self, query_embedding, collection="policy_semantic", top_k=5):
        results = self.qdrant.search(
            collection_name=collection,
            query_vector=query_embedding.tolist(),
            limit=top_k
        )
        return [(hit.payload['text'], hit.score) for hit in results]

# Create the index
policy_index = MultimodalPolicyIndex(policy_embeddings)
print("Policy index created and ready")

def analyze_image_comprehensive(image_path):
    image = Image.open(image_path).convert('RGB')

    # Get CLIP embedding
    clip_embedding = embed_image(image)

    # Generate caption if BLIP available
    caption = None
    if use_blip:
        image_processed = vis_processors["eval"](image).unsqueeze(0).to(device)
        caption = blip_model.generate({"image": image_processed})[0]

    # Extract visual concepts using CLIP
    concepts_to_check = [
        "adult content", "violence", "weapons", "drugs", "alcohol",
        "misleading graphics", "fake testimonials", "copyright infringement",
        "medical claims", "financial promises", "luxury goods", "children"
    ]

    concept_scores = {}
    for concept in concepts_to_check:
        concept_emb = embed_text_clip(concept)
        score = np.dot(clip_embedding, concept_emb)
        concept_scores[concept] = float(score)

    return {
        'embedding': clip_embedding,
        'caption': caption,
        'concept_scores': concept_scores,
        'top_concerns': sorted(concept_scores.items(), key=lambda x: x[1], reverse=True)[:5]
    }

class MultimodalComplianceEngine:
    def __init__(self, policy_index: MultimodalPolicyIndex):
        self.policy_index = policy_index
        self.violation_keywords = {
            'high_risk': ['guaranteed', '100%', 'cure', 'miracle', 'risk-free'],
            'medium_risk': ['limited time', 'act now', 'exclusive', 'secret'],
            'low_risk': ['best', 'top', 'number one', 'revolutionary']
        }

    def analyze_text(self, text):
        # Semantic embedding
        text_emb = embed_text_semantic(text)

        # Find relevant policies
        relevant_policies = self.policy_index.search_policies(text_emb, "policy_semantic", 3)

        # Check for violations
        violations = []
        risk_level = 'low'

        text_lower = text.lower()
        for level, keywords in self.violation_keywords.items():
            for keyword in keywords:
                if keyword in text_lower:
                    violations.append({'keyword': keyword, 'risk': level})
                    if level == 'high_risk':
                        risk_level = 'high'
                    elif level == 'medium_risk' and risk_level != 'high':
                        risk_level = 'medium'

        return {
            'embedding': text_emb,
            'violations': violations,
            'risk_level': risk_level,
            'relevant_policies': relevant_policies
        }

    def analyze_multimodal(self, text, image_path=None):
        # Text analysis
        text_results = self.analyze_text(text)

        results = {
            'text_analysis': text_results,
            'compliance_score': 10.0,
            'final_risk': text_results['risk_level']
        }

        # Deduct points for text violations
        for violation in text_results['violations']:
            if violation['risk'] == 'high_risk':
                results['compliance_score'] -= 2.0
            elif violation['risk'] == 'medium_risk':
                results['compliance_score'] -= 1.0
            else:
                results['compliance_score'] -= 0.5

        # Image analysis if provided
        if image_path:
            image_results = analyze_image_comprehensive(image_path)
            results['image_analysis'] = image_results

            # Check image concerns
            for concept, score in image_results['top_concerns']:
                if score > 0.3 and any(risk in concept for risk in ['adult', 'violence', 'weapons', 'drugs']):
                    results['compliance_score'] -= 3.0
                    results['final_risk'] = 'high'
                elif score > 0.25:
                    results['compliance_score'] -= 1.0

            # Cross-modal consistency check
            if image_results['caption']:
                caption_emb = embed_text_semantic(image_results['caption'])
                text_image_similarity = np.dot(text_results['embedding'], caption_emb) / (
                    np.linalg.norm(text_results['embedding']) * np.linalg.norm(caption_emb)
                )

                if text_image_similarity < 0.3:
                    results['compliance_score'] -= 1.5
                    results['text_image_mismatch'] = True

        results['compliance_score'] = max(0, min(10, results['compliance_score']))
        results['pass'] = results['compliance_score'] >= 7.0

        return results

import pickle

compliance_engine = MultimodalComplianceEngine(policy_index)

# Test with problematic ad
test_cases = [
    {
        'text': "Lose 30 pounds in 30 days! Guaranteed results with our miracle pill. 100% natural!",
        'expected': 'fail'
    },
    {
        'text': "Professional web hosting services with 99.9% uptime guarantee and 24/7 support.",
        'expected': 'pass'
    },
    {
        'text': "Limited time offer! Act now! Exclusive deal only for you!",
        'expected': 'warn'
    }
]

for test in test_cases:
    print(f"\nTesting: {test['text'][:50]}...")
    result = compliance_engine.analyze_multimodal(test['text'])
    print(f"Score: {result['compliance_score']:.1f}/10")
    print(f"Risk: {result['final_risk']}")
    print(f"Pass: {result['pass']}")
    print(f"Violations: {len(result['text_analysis']['violations'])}")

# Cell 22: Save Complete Model State
def save_complete_state(compliance_engine, policy_embeddings, filepath="compliance_model_state.pkl"):
    state = {
        'policy_embeddings': {
            'text': policy_embeddings.text_embeddings,
            'clip': policy_embeddings.clip_text_embeddings,
            'chunks': policy_embeddings.chunks,
            'metadata': policy_embeddings.metadata
        },
        'violation_keywords': compliance_engine.violation_keywords,
        'timestamp': str(np.datetime64('now'))
    }

    with open(filepath, 'wb') as f:
        pickle.dump(state, f)

    print(f"Saved complete model state to {filepath}")
    return filepath

# Save the state
model_file = save_complete_state(compliance_engine, policy_embeddings)

# Cell 23: Load and Restore Model State
def load_complete_state(filepath="compliance_model_state.pkl"):
    with open(filepath, 'rb') as f:
        state = pickle.load(f)

    # Reconstruct PolicyEmbeddings
    policy_emb = PolicyEmbeddings(
        text_embeddings=state['policy_embeddings']['text'],
        clip_text_embeddings=state['policy_embeddings']['clip'],
        chunks=state['policy_embeddings']['chunks'],
        metadata=state['policy_embeddings']['metadata']
    )

    # Rebuild index and engine
    policy_idx = MultimodalPolicyIndex(policy_emb)
    engine = MultimodalComplianceEngine(policy_idx)
    engine.violation_keywords = state['violation_keywords']

    print(f"Restored model state from {filepath}")
    return engine, policy_emb

# Test loading
restored_engine, restored_embeddings = load_complete_state(model_file)
print(f"Successfully restored {len(restored_embeddings.chunks)} policy chunks")

!ls

